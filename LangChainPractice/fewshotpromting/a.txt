stepback_question What specific GCP Cloud Function trigger should be used for this code conversion?
examples [{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error)).', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}]
few_shot_prompt_template input_variables=['request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error)).', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['output_code', 'request'], template='\nrequest: {request}\n{output_code}\n') suffix='\nrequest: {request}\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What specific GCP service should the AWS Lambda function be converted to?
examples [{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\n import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}]
few_shot_prompt_template input_variables=['request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\n import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['output_code', 'request'], template='\nrequest: {request}\n{output_code}\n') suffix='\nrequest: {request}\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What specific GCP service should the AWS Lambda function be converted to?
examples [{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\n import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = f\'{\'Bucket\': {source_bucket}, \'Key\': {key}}\'\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}]
few_shot_prompt_template input_variables=['request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\n import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = f\'{\'Bucket\': {source_bucket}, \'Key\': {key}}\'\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['output_code', 'request'], template='\nrequest: {request}\n{output_code}\n') suffix='\nrequest: {request}\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What specific GCP service should the AWS Lambda function be converted to?
examples [{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\n import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}]
few_shot_prompt_template input_variables=['request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\n import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['output_code', 'request'], template='\nrequest: {request}\n{output_code}\n') suffix='\nrequest: {request}\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What specific GCP service should the code be converted to?
stepback_question What specific GCP Cloud Function trigger should be used for this code conversion?
stepback_question What specific GCP service should the AWS Lambda function be converted to?
stepback_question What specific GCP service should the AWS Lambda function be converted to?
stepback_question What specific GCP service should the AWS Lambda function be converted to?
stepback_question What specific GCP service should the AWS Lambda function be converted to?
few_shot_prompt_template input_variables=['input_code'] examples=[{'User': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.', 'input_code': 'import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = f\'{\'Bucket\': {source_bucket}, \'Key\': {key}}\'\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code'], template='\nUser: Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\ninput_code: {input_code}\nanswer: {output_code}\n') suffix='\nUser: Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What specific GCP service should the AWS Lambda function be converted to?
few_shot_prompt_template input_variables=['input_code'] examples=[{'User': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.', 'input_code': 'import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = """{\'Bucket\': {source_bucket}, \'Key\': {key}}"""\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code'], template='\nUser: Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\ninput_code: {input_code}\nanswer: {output_code}\n') suffix='\nUser: Convert the given AWS Lambda Python Function to GCP Cloud Function in Python.\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What are the specific trigger and event details for the AWS Lambda Python Function that need to be considered for conversion to GCP Cloud Function in Python?
stepback_question What are the specific trigger and event details for the AWS Lambda function that need to be replicated in the GCP Cloud Function?
stepback_question What are the specific triggers or events that should invoke the Cloud Function in GCP?
stepback_question What are the specific trigger and event details for the AWS Lambda Python Function that need to be considered for conversion to GCP Cloud Function in Python?
stepback_question What are the specific trigger and event details for the AWS Lambda function that need to be considered for conversion to a GCP Cloud Function?
stepback_question What are the specific trigger and event details for the AWS Lambda Python function that need to be considered for conversion to a GCP Cloud Function in Python?
stepback_question What are the specific trigger and event details for the AWS Lambda Python Function that need to be considered for conversion to GCP Cloud Function in Python?
stepback_question What are the specific trigger or event source details for the function?
few_shot_prompt input_variables=['input_code', 'request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python', 'input_code': '"""\nimport boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))\n"""', 'output_code': '"""\nfrom google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"\n"""'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code', 'request'], template='\nUser: {request}\ninput_code: {input_code}\noutput_code: {output_code}\n') suffix='\nUser: {request}\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What are the specific triggers or events that should invoke the Cloud Function in GCP?
few_shot_prompt input_variables=['input_code', 'request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python', 'input_code': 'import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code', 'request'], template='\nUser: {request}\ninput_code: {input_code}\noutput_code: {output_code}\n') suffix='\nUser: {request}\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What are the specific triggers or events that should invoke the Cloud Function in GCP?
few_shot_prompt input_variables=['input_code', 'request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python', 'input_code': '{{\nimport boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))\n}}', 'output_code': '{{\nfrom google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"\n}}'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code', 'request'], template='\nUser: {request}\ninput_code: {input_code}\noutput_code: {output_code}\n') suffix='\nUser: {request}\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What are the specific dependencies or libraries used in the AWS Lambda Python function that need to be considered for conversion to GCP Cloud Function?
few_shot_prompt input_variables=['input_code', 'request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python', 'input_code': 'import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code', 'request'], template='\nUser: {request}\ninput_code: {input_code}\noutput_code: {output_code}\n') suffix='\nUser: {request}\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
stepback_question What are the specific AWS Lambda triggers and permissions used in the given Python function code?
few_shot_prompt input_variables=['input_code', 'request'] examples=[{'request': 'Convert the given AWS Lambda Python Function to GCP Cloud Function in Python', 'input_code': 'import boto3\nimport botocore\nimport json\nimport os\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ns3 = boto3.resource(\'s3\')\n\ndef lambda_handler(event, context):\n    logger.info("New files uploaded to the source bucket.")\n        \n    key = event[\'Records\'][0][\'s3\'][\'object\'][\'key\']\n        \n    source_bucket = event[\'Records\'][0][\'s3\'][\'bucket\'][\'name\']\n    destination_bucket = os.environ[\'destination_bucket\']\n    \n    source = {\'Bucket\': source_bucket, \'Key\': key}\n        \n    try:\n        response = s3.meta.client.copy(source, destination_bucket, key)\n        logger.info("File copied to the destination bucket successfully!")\n        \n    except botocore.exceptions.ClientError as error:\n        logger.error("There was an error copying the file to the destination bucket")\n        print(\'Error Message: {}\'.format(error))\n        \n    except botocore.exceptions.ParamValidationError as error:\n        logger.error("Missing required parameters while calling the API.")\n        print(\'Error Message: {}\'.format(error))', 'output_code': 'from google.cloud import storage\n\ndef copy_bucket_files(request):\n    """\n    Copies the files from a specified bucket into the selected one.\n    """\n\n    # Check if the bucket\'s name was specified in the request\n    if request.args.get(\'bucket\'):\n        bucketName = request.args.get(\'bucket\')\n    else:\n        return "The bucket name was not provided. Please try again."\n\n    try:\n        # Initiate Cloud Storage client\n        storage_client = storage.Client()\n        # Define the origin bucket\n        origin = storage_client.bucket(bucketName)\n        # Define the destination bucket\n        destination = storage_client.bucket(\'<my-test-bucket>\')\n\n        # Get the list of the blobs located inside the bucket which files you want to copy\n        blobs = storage_client.list_blobs(bucketName)\n\n        for blob in blobs:\n            origin.copy_blob(blob, destination)\n\n        return "Done!"\n\n    except:\n        return "Failed!"'}] example_prompt=PromptTemplate(input_variables=['input_code', 'output_code', 'request'], template='\nUser: {request}\ninput_code: {input_code}\noutput_code: {output_code}\n') suffix='\nUser: {request}\ninput_code: {input_code}\nAI:\n' prefix='\nYou are a code converter tool which converts code for a specific service from one cloud platform to a service on another cloud platform.\nYou have received request that contains the input code, the service name, the source cloud platform, the target service and cloud platform.\nUse the given pieces of context to convert the code and generate output code for target service on target cloud platform.\nIf you don\'t understant the context look for relevant information from your knowlegde base. Do not return an empty string ("").\n'
